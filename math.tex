\usepackage{bbm}
\usepackage{bm}
\usepackage{bbold}
\usepackage{siunitx}
\usepackage{amsmath,amssymb,amsfonts}

%% Scirob
\DeclareMathOperator*{\find}{find}
\newcommand{\subjectto}{\text{subject to}}
\newcommand{\paccept}{0.5}
\newcommand{\goal}{\mathcal{G}}
\newcommand{\env}{\mathcal{E}}
\newcommand{\benv}{\bm{\env}}
\newcommand{\localenv}{\env_l}
\newcommand{\state}{s}
\newcommand{\bstate}{\bm{\state}}
\newcommand{\action}{a}
\newcommand{\baction}{\bm{\action}}
\newcommand{\statefull}{\state=[x_{g1},y_{g1},z_{g1},\dots,x_{g\NGrippers},y_{g\NGrippers},z_{g\NGrippers}, x_1,y_1,z_1,\dots,x_{\NLinks},y_{\NLinks},z_{\NLinks}]}
\newcommand{\nensemble}{N_{e}}
\newcommand{\statespace}{\mathcal S}
\newcommand{\modelerrorthreshold}{\delta}
\newcommand{\distfname}{\mathrm{dist}}
\newcommand{\distf}[2]{\distfname(#1,#2)}
\newcommand{\pred}[1]{\hat{#1}}
\newcommand{\statepred}{\pred{\state}}
\newcommand{\currentstate}{\state^{t}}
\newcommand{\nextdeltastate}{\Delta\state^{t+1}}
\newcommand{\currentstatepred}{\statepred^{t}}
\newcommand{\nextstate}{\state^{t+1}}
\newcommand{\nextstatepred}{\statepred^{t+1}}
\newcommand{\horizon}{N}
\newcommand{\trainhorizon}{\horizon_{t}}
\newcommand{\lasttrainaction}{\action^{\horizon_{t}-1}}
\newcommand{\lasttrainstate}{\state^{\horizon_{t}}}
\newcommand{\actionSpace}{\mathcal{A}}
\newcommand{\lastaction}{\action^{\horizon-1}}
\newcommand{\laststate}{\state^{\horizon}}
\newcommand{\laststatepred}{\statepred^{\horizon}}
\newcommand{\currentaction}{\action^{t}}
\newcommand{\dynamics}{f}
\newcommand{\transitionpred}{\currentstatepred,\currentaction,\nextstatepred}
\newcommand{\worlddynamicsfunc}{\dynamics(\env,\currentstate,\currentaction)}
\newcommand{\worlddynamicsdef}{\worlddynamicsfunc\rightarrow\nextstate}
\newcommand{\worlddynamics}{\dynamics}
\newcommand{\ourdynamicsfunc}{h(\env,\currentstatepred,\currentaction)}
\newcommand{\ourdynamicsdef}{\ourdynamicsfunc\rightarrow\nextstatepred}
\newcommand{\ourdynamics}{h}
\newcommand{\classifier}{g}
\newcommand{\modelerror}{\distf{\nextstatepred}{\nextstate}}
\newcommand{\MER}{\modelerror < \modelerrorthreshold}
\newcommand{\modelerrorconstraint}{\modelerror < \modelerrorthreshold}
\newcommand{\modelerrordef}{\modelerror = \distf{\ourdynamicsfunc}{\worlddynamicsfunc}}
\newcommand{\variance}{\sigma^2}
\newcommand{\classifierInputs}{\texttt{INPUT}\xspace}
\newcommand{\classifierProb}{p_c}
\newcommand{\classifierLabel}{\texttt{LABEL}\xspace}
\newcommand{\classifierfuncfull}{\classifier(\env, \currentstatepred,\currentaction,\nextstatepred,\variance)}
\newcommand{\classifierfuncNoVar}{\classifier(\env, \currentstatepred,\currentaction,\nextstatepred)}
\newcommand{\classifierdef}{\classifierfuncfull \rightarrow \classifierProb \in \{0,1\}}
\newcommand{\classifierdefNoVar}{\classifierfuncNoVar \rightarrow \{0,1\}}
\newcommand{\recovProb}{p_r}
\newcommand{\recovInputs}{(\localenv,\currentstate,\currentaction)}
\newcommand{\recoveryfunc}{r}
\newcommand{\recoveryfuncfull}{\recoveryfunc(\env,\currentstate)}
\newcommand{\recoverydef}{\recoveryfuncfull \rightarrow \{0,1\}}
\newcommand{\NRecoverySamples}{N_\text{rs}}
\newcommand{\NGrippers}{N_\text{g}}
\newcommand{\NLinks}{N_\text{rl}}
\newcommand{\Ndim}{N_d}
\newcommand{\reals}{\mathbb{R}}


%% RSS
\newcommand{\nStep}{N_p}
\newcommand{\mProj}{M_p}
\newcommand{\robot}{q}
\newcommand{\classLabel}{w}
\newcommand{\transform}{T}
\newcommand{\aug}[1]{\Tilde{#1}}
\newcommand{\test}[1]{{#1}'}
\newcommand{\target}[1]{#1^\text{target}}
\newcommand{\example}{x}
\newcommand{\exampleSpace}{\mathcal{X}}
\newcommand{\relevantSet}{\mathcal{X}_r}
\newcommand{\validSet}{\mathcal{X}_v}
\newcommand{\augf}{\phi}
\newcommand{\augDef}{\augf:\exampleSpace\rightarrow\exampleSpace}
\newcommand{\bsrae}{\bstate,\bm{\robot},\baction,\benv}
\newcommand{\bsraeAug}{\bm{\aug{\state}},\bm{\aug{\robot}},\bm{\aug{\action}},\benv}
\newcommand{\newAugDef}{\augf(\bsrae)\rightarrow\{\bsraeAug\}}
\newcommand{\rollout}{\rho}
\newcommand{\exampleAug}{\aug{\example}}
\newcommand{\nAug}{k}
\newcommand{\transformSet}{\transform_{1:\nAug}}
\newcommand{\exampleAugSet}{\exampleAug_{1:\nAug}}
\newcommand{\transformDist}{p_{\exampleAugSet}(\transform)}
\newcommand{\transformUniformRange}{[\transform^-,\transform^+]}
\newcommand{\uniform}{\mathbb{U}}
\newcommand{\transformUniform}{\uniform\transformUniformRange}
\newcommand{\loss}{\mathcal{L}}
\newcommand{\lossRobot}{\loss_\text{robot}}
\newcommand{\lossBbox}{\loss_\text{bbox}}
\newcommand{\lossValid}{\loss_\text{valid}}
\newcommand{\lossOcc}{\loss_\text{occ}}
\newcommand{\validF}{f_\text{valid}}
\newcommand{\learnedValidF}{f_{\text{valid},\theta}(\transform)}
\newcommand{\minDist}{{d^-}}
\newcommand{\betaBbox}{\beta_1}
\newcommand{\betaValid}{\beta_2}
\newcommand{\betaOcc}{\beta_3}
\newcommand{\betaDmd}{\beta_4}
\newcommand{\lossDmd}{\loss_{\Delta\minDist}}
\newcommand{\lossGrad}{\nabla_\transform\loss}
\newcommand{\projectionNotProgressing}{\delta_p}
\newcommand{\projLr}{\alpha_p}
\newcommand{\projStepSizeThreshold}{\epsilon_p}
\newcommand{\points}{p}
\newcommand{\contactpoint}{p^c}
\newcommand{\statePoint}{\points_{\state,i}}
\newcommand{\augStatePoint}{\aug{\points}_{\state,i}}
\newcommand{\statePoints}{\points_\state}
\newcommand{\augStatePoints}{\aug{\points}_\state}
\newcommand{\pointMinDist}{p_\minDist}
\newcommand{\augPointMinDist}{\aug{p}_\minDist}
\newcommand{\pointDist}{d}
\newcommand{\distPointMinDist}{\pointDist^-}
\newcommand{\distAugPointMinDist}{\aug{\pointDist}^-}
\newcommand{\augMovedObjPoints}{\aug{p}_m}
\newcommand{\envPoints}{p_\env}
\newcommand{\SDF}{\mathrm{SDF}}
\newcommand{\sdfGrad}{\nabla{\SDF}}
\newcommand{\learnValidError}{y_\text{valid}}
\newcommand{\minLearnValidError}{\learnValidError^-}
\newcommand{\learnValidDataset}{\mathcal{D}_\text{valid}}
\newcommand{\transformDim}{d}
\newcommand{\learnValidScaling}{\alpha_\text{valid}}
\newcommand{\nLearnValid}{n_\text{valid}}
\newcommand{\sampleTransform}{\texttt{sample\_transform}}
\newcommand{\learnValidTestStates}{\mathcal{S}_\text{valid}}
\newcommand{\learnValidTestActions}{\mathcal{A}_\text{valid}}
\newcommand{\projectArgs}{\state,\action,\env,\transform}
\newcommand{\klF}{D_{KL}}
\newcommand{\kl}[2]{\klF({#1}\,||\,{#2})}
\newcommand{\uniformity}{e^{-\kl{\transformDist}{\transformUniform}}}
\newcommand{\apply}{\texttt{apply}}
\newcommand{\applyState}{\texttt{apply\_state}}
\newcommand{\sample}{\texttt{sample}}
\newcommand{\augState}{\texttt{aug\_state}}
\newcommand{\augRobot}{\texttt{aug\_robot}}
\newcommand{\learnValidSimF}{\texttt{simulate}}
\newcommand{\lossDiversity}{\loss_\uniform}
\newcommand{\learnValidStateActionSet}{Q_\text{valid}}

%% ICRA 23
\newcommand{\MDE}{h}
\newcommand{\dynamicsErrort}{||\currentstatepred-\currentstate||^2}
\newcommand{\mdeError}{d}
\newcommand{\subSource}[1]{#1_S}
\newcommand{\subTarget[1]}{#1_T}
\newcommand{\learned}[1]{\hat{#1}}
\newcommand{\sourceDynamics}{\subSource{\dynamics}}
\newcommand{\targetDynamics}{\subTarget{\dynamics}}
\newcommand{\learnedDynamics}{\learned{\dynamics}}
\newcommand{\learnedDynamicsDef}{\statepred'=\learnedDynamics(\state,\action)}
\newcommand{\dataset}{\mathcal{D}}
\newcommand{\DST}{\dataset_{ST}}
\newcommand{\traj}{\{\state^0,\action^0,\dots,\action^{T-1},\state^T\}}
\newcommand{\softFilteringThrehsold}{\gamma}
\newcommand{\globalStep}{j}
\newcommand{\dmax}{d_\text{max}}
\newcommand{\transition}{(\state,\action,\state')}
\newcommand{\kMDE}{k_\MDE}

%% ICRA 24
\newcommand{\sig}{{\mathcal{G}_L}}
\newcommand{\q}{q}
\newcommand{\loc}{l}
\newcommand{\locs}{\bm{l}}
\newcommand{\kp}{\loc_k}
\newcommand{\subGoal}[1]{#1_\text{goal}}
\newcommand{\goalPoint}{\subGoal{p}}
\newcommand{\goalRadius}{\subGoal{d}}
\newcommand{\goalSig}{\subGoal{\sig{}}}
\newcommand{\qvel}{\dot{q}}
\newcommand{\grasp}{g}
\newcommand{\graspElem}{\grasp_i}
\newcommand{\skels}{\textbf{S}}
\newcommand{\skel}{\mathit{S}}
\newcommand{\sk}{\textbf{s}}
\newcommand{\epsl}{\epsilon_l}
\newcommand{\maxIters}{i^\text{max}}
\newcommand{\graspLoop}{\bm{\tau}}
\newcommand{\planGrasp}{\textit{PlanGrasp}}
\newcommand{\indic}{\mathbb{1}}
\newcommand{\isGrasping}{\bm{\indic_g}}
\newcommand{\ncon}{n_\text{con}}
\newcommand{\blist}{\mathcal{B}}
\newcommand{\goalFunc}{\subGoal{\indic}}
\newcommand{\goalCost}{\subGoal{C}}
\newcommand{\graspCost}{C_\text{grasp}}
\newcommand{\getValidCycles}{\texttt{getValidCycles}}
\newcommand{\addEdges}{\texttt{addEdges}}
\newcommand{\getLoops}{\texttt{getLoops}}
\newcommand{\Adj}{\text{Adj}}
\newcommand{\cycles}{\mathcal{O}}
